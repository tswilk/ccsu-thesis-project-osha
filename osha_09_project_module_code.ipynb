{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load osha_project.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "from matplotlib.path import Path\n",
      "import matplotlib.patches as patches\n",
      "import matplotlib.ticker as ticker\n",
      "import cPickle as pickle\n",
      "from time import gmtime, strftime, time\n",
      "import os, warnings, collections, csv, nltk, re, requests, zipfile\n",
      "from dateutil import parser\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
      "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
      "from sklearn import preprocessing\n",
      "from sklearn.decomposition import PCA, TruncatedSVD\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.preprocessing import Normalizer\n",
      "\n",
      "from gensim import corpora, models, similarities\n",
      "\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "project_dir = './project/'\n",
      "structured_dir = project_dir + 'structured/'\n",
      "keyword_dir = project_dir + 'keyword/'\n",
      "linguistic_dir = project_dir + 'linguistic/'\n",
      "topic_dir = project_dir + 'topic/'\n",
      "svd_description_dir = project_dir + 'svd_description/'\n",
      "svd_summary_dir = project_dir + 'svd_summary/'\n",
      "combined_dir = project_dir + 'combined/'\n",
      "\n",
      "all_dirs = [project_dir, structured_dir, keyword_dir, linguistic_dir, topic_dir,\n",
      "            svd_description_dir, svd_summary_dir, combined_dir]\n",
      "\n",
      "for each_dir in all_dirs:\n",
      "    if not os.path.exists(each_dir):\n",
      "        os.makedirs(each_dir)\n",
      "\n",
      "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
      "english_lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
      "english_stopwords = nltk.corpus.stopwords.words('english')\n",
      "punctuation = re.compile(r'[.?!,\":;()#\\'|0-9]')\n",
      "\n",
      "def get_stemmed_exlude_tokens():\n",
      "    exclude_tokens = ['die', 'dying', 'death', 'dead', 'decease', 'killed', 'demise', 'suffocate', 'electrocute',\n",
      "                      'drown', 'fatal', 'asphyxiate', 'asphyxia', 'employee', 'hospital']\n",
      "    stemmed_exclude_tokens = set([english_stemmer.stem(t) for t in exclude_tokens])\n",
      "    return stemmed_exclude_tokens\n",
      "\n",
      "def get_classifiers():\n",
      "    clfs = {'AdaBst': AdaBoostClassifier(), 'LogReg': LogisticRegression(), 'RanFst': RandomForestClassifier(),\n",
      "            'DTree': DecisionTreeClassifier(), 'KNN': KNeighborsClassifier()}\n",
      "    return clfs\n",
      "\n",
      "def get_partition_sets(df_struct, test_set_proportion):\n",
      "    validation_set = df_struct[df_struct.event_year > 2008].fatality_ind\n",
      "    train_test_set = df_struct[df_struct.event_year <= 2008].fatality_ind\n",
      "    train_test_set_shuffled = train_test_set.reindex(np.random.permutation(train_test_set.index))\n",
      "    train_cutoff = len(train_test_set)-int((test_set_proportion * len(train_test_set)))\n",
      "    train_set = train_test_set_shuffled[:train_cutoff]\n",
      "    test_set = train_test_set_shuffled[train_cutoff:]\n",
      "    train_set = pd.DataFrame({'fatality_ind':train_set, 'partition':'train'}, index = train_set.index)\n",
      "    test_set = pd.DataFrame({'fatality_ind':test_set, 'partition':'test'}, index = test_set.index)\n",
      "    validation_set = pd.DataFrame({'fatality_ind':validation_set, 'partition':'validation'}, index = validation_set.index)\n",
      "    df_partition = pd.concat([train_set, test_set, validation_set])\n",
      "    df_partition.index.name = 'summary_nr'\n",
      "    df_partition.sort_index(inplace=True)\n",
      "    return df_partition\n",
      "\n",
      "def get_partition(df, partition):\n",
      "    return df[df.partition == partition]\n",
      "\n",
      "def get_top_k_features(df, score_fn, k):\n",
      "    X_train = get_partition(df,'train').drop(['fatality_ind','partition'],axis=1)\n",
      "    y_train = get_partition(df,'train').fatality_ind\n",
      "    selector = SelectKBest(score_func=score_fn,k=k)\n",
      "    selector.fit(X_train, y_train)\n",
      "    scores = -np.log10(selector.pvalues_)\n",
      "    df_top_features = pd.DataFrame({'scores':scores, 'feature':X_train.columns}).sort('scores',ascending=False)\n",
      "    return df_top_features[:k]\n",
      "\n",
      "\n",
      "def get_excluded_words():\n",
      "    lst = ['asphyxia', 'asphyxiant', 'asphyxiate', 'asphyxiated', 'asphyxiates', 'asphyxiating', 'asphyxiation', 'dead',\n",
      "           'deadly', 'death', 'deaths', 'decease', 'deceased', 'demise', 'die', 'died', 'dies', 'drown', 'drowned',\n",
      "           'drownes', 'drowning', 'drowns', 'dying', 'electrocute', 'electrocuted', 'electrocutes', 'electrocuting',\n",
      "           'electrocution', 'electrocutions', 'employee', 'employees', 'employee\\'s', 'employee #1', 'employee #1\\'s',\n",
      "           'fatal', 'fatalities', 'fatality', 'fatally', 'hospitable', 'hospital', 'hospitality', 'hospitalization',\n",
      "           'hospitalizations', 'hospitalize', 'hospitalized', 'hospitalizes', 'hospitalizing', 'hospitals', 'kill',\n",
      "           'kille', 'killed', 'killing', 'kills', 'suffocate', 'suffocated', 'suffocates', 'suffocating', 'suffocation']\n",
      "    lst.sort(key=len, reverse=True)\n",
      "    return lst\n",
      "\n",
      "\n",
      "def get_accident_detail_url(inspection_id):\n",
      "    accident_detail_url_prefix = 'https://www.osha.gov/pls/imis/establishment.inspection_detail?id='\n",
      "    return accident_detail_url_prefix + str(inspection_id)\n",
      "\n",
      "\n",
      "def clean_keyword(keywords, empty_return_phrase='___EMPTY___'):\n",
      "    exclude_words = get_excluded_words()\n",
      "    kws = keywords.lower().split(',')\n",
      "    cleaned = ','.join([k for k in kws if k not in exclude_words])\n",
      "    if cleaned == '':\n",
      "        cleaned = empty_return_phrase\n",
      "    return cleaned\n",
      "\n",
      "\n",
      "def clean_text(raw_txt, empty_return_phrase='___EMPTY___'):\n",
      "    exclude_words = get_excluded_words()\n",
      "    txt = raw_txt.lower()\n",
      "    for word in exclude_words:\n",
      "        txt = txt.replace(word, '')\n",
      "    cleaned = ' '.join(txt.split()).strip()\n",
      "    if cleaned == '':\n",
      "        cleaned = empty_return_phrase\n",
      "    return cleaned\n",
      "\n",
      "\n",
      "def get_description_vectorizer_info():\n",
      "    vlist = [['Description - Stem - Ngrams 1 Only', 'desc_stem_n1', 5, (1, 1), 'stem'],\n",
      "             ['Description - Stem - Ngrams 1,2,3', 'desc_stem_n123', 5, (1, 3), 'stem'],\n",
      "             ['Description - Lemma - Ngrams 1 Only', 'desc_lem_n1', 5, (1, 1), 'lemma'],\n",
      "             ['Description - Lemma - Ngrams 1,2,3', 'desc_lem_n123', 5, (1, 3), 'lemma']]\n",
      "    return vlist\n",
      "\n",
      "def get_summary_vectorizer_info():\n",
      "    vlist = [['Summary - Stem - Ngrams 1 Only', 'summ_stem_n1', 20, (1, 1), 'stem'],\n",
      "             ['Summary - Stem - Ngrams 1,2,3', 'summ_stem_n123', 20, (1, 3), 'stem'],\n",
      "             ['Summary - Lemma - Ngrams 1 Only', 'summ_lem_n1', 20, (1, 1), 'lemma'],\n",
      "             ['Summary - Lemma - Ngrams 1,2,3', 'summ_lem_n123', 20, (1, 3), 'lemma']]\n",
      "    return vlist\n",
      "\n",
      "def get_vectorizer(min_df, ngram_range, morphtype):\n",
      "    if morphtype == 'lemma':\n",
      "        return LemmatizedTfidfVectorizer(min_df=min_df, stop_words=english_stopwords, ngram_range=ngram_range)\n",
      "    else:\n",
      "        return StemmedTfidfVectorizer(min_df=min_df, stop_words=english_stopwords, ngram_range=ngram_range)\n",
      "\n",
      "\n",
      "def plot_accident_by_year(df_acc, norm=False, save=False):\n",
      "    xtab = pd.crosstab(df_acc.event_year, df_acc.fatality_ind)\n",
      "    xtab.columns = ['Not Fatal', 'Fatal']\n",
      "    xtab.columns.name = 'Accident Outcome'\n",
      "    ylabel = 'Accident Count'\n",
      "    if norm:\n",
      "        xtab = xtab.div(xtab.sum(axis=1).astype('float'), axis=0)\n",
      "        ylabel = 'Accident Percent'\n",
      "    fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
      "    xtab.plot(kind='bar', ax=axes, stacked=True, alpha=0.5, sort_columns=True)\n",
      "    axes.set_title('OSHA Accident Investigations')\n",
      "    axes.set_ylabel(ylabel)\n",
      "    axes.set_xlabel('Event Year')\n",
      "    if save:\n",
      "        plt.savefig(structured_dir + 'osha_accident_by_year_plot.png')\n",
      "\n",
      "\n",
      "def plot_time_visuals(df_struct, save=False):\n",
      "    time_vars = ['event_year', 'event_month', 'event_weekday', 'event_hour']\n",
      "    time_labels = [[str(x)[2:] for x in range(1990, 2013)],\n",
      "                   ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
      "                   ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n",
      "                   ['12a'] + [str(x) + 'a' for x in range(1, 12)] + ['12p'] + [str(x - 12) + 'p' for x in\n",
      "                                                                               range(13, 24)]]\n",
      "    fig, axes = plt.subplots(4, 2, figsize=(10, 10))\n",
      "    xtab_col = np.array(time_vars)\n",
      "    lbls_col = np.array(time_labels)\n",
      "    for i in range(4):\n",
      "        xtab = pd.crosstab(df_struct[xtab_col[i]], df_struct.fatality_ind)\n",
      "        xtab.columns = ['Not Fatal', 'Fatal']\n",
      "        #xtab.columns.name='Accident Outcome'\n",
      "        norm_xtab = xtab.div(xtab.sum(axis=1).astype('float'), axis=0)\n",
      "        xtab.plot(kind='bar', ax=axes[i, 0], alpha=0.5, legend=False, sort_columns=True)\n",
      "        norm_xtab.plot(kind='bar', stacked=True, ax=axes[i, 1], alpha=0.5, sort_columns=True)\n",
      "        xlabel = xtab_col[i].replace('_', ' ').title()\n",
      "        axes[i, 0].set_title('Accident Outcome by %s' % xlabel)\n",
      "        axes[i, 1].set_title('Normalized Histogram of %s' % xlabel)\n",
      "        axes[i, 0].set_xlabel(xlabel)\n",
      "        axes[i, 1].set_xlabel(xlabel)\n",
      "        axes[i, 0].set_ylabel('Accident Count')\n",
      "        axes[i, 1].set_ylabel('Portion of Accidents')\n",
      "        axes[i, 1].legend(loc=\"lower left\")\n",
      "        axes[i, 0].set_xticklabels(lbls_col[i], rotation=(60 if i == 3 else 0))\n",
      "        axes[i, 1].set_xticklabels(lbls_col[i], rotation=(60 if i == 3 else 0))\n",
      "    fig.tight_layout(pad=0.4, w_pad=1.0, h_pad=1.0)\n",
      "    if save:\n",
      "        plt.savefig(structured_dir + 'osha_time_plots.png')\n",
      "\n",
      "\n",
      "def plot_categorical_heatmaps(df_struct, top_n=30, norm=False, save=False):\n",
      "    struct_cat_vars = ['nature_of_inj', 'part_of_body', 'src_of_injury', 'event_type', 'evn_factor',\n",
      "                       'hum_factor', 'occ_code', 'sic_desc']\n",
      "    vars_desc = {'site_state': 'Site State', 'site_city': 'Site City', 'nature_of_inj': 'Nature of Injury',\n",
      "             'part_of_body': 'Part of Body', 'src_of_injury': 'Source of Injury', 'event_type': 'Event Type',\n",
      "             'evn_factor': 'Event Factor', 'hum_factor': 'Human Factor', 'occ_code': 'Occupation',\n",
      "             'sic_desc': 'SIC Group Description'}\n",
      "    for i, cat_var in enumerate(struct_cat_vars):\n",
      "        df_filter = df_struct[df_struct.event_year <= 2008]\n",
      "        df = df_filter.pivot_table('fatality_ind', rows=[cat_var], cols=['event_year'], aggfunc='sum').fillna(0)\n",
      "        df.index.name = cat_var\n",
      "        num_cats = df.shape[0]\n",
      "        if norm:\n",
      "            df = (df - df.mean()) / (df.max() - df.min())\n",
      "        df_sort = df.sort_index(by=[2008], ascending=False)[:top_n].T\n",
      "        fig, ax = plt.subplots()\n",
      "        im = ax.pcolor(df_sort, cmap=plt.cm.YlOrRd)\n",
      "        cbar = fig.colorbar(im)\n",
      "        cbar.set_label('# of Fatalities', rotation=90, size=16)\n",
      "        if num_cats <= top_n:\n",
      "            prefix = 'All ' + str(num_cats)\n",
      "        else:\n",
      "            prefix = 'Top ' + str(top_n)\n",
      "        ax.set_xlabel(vars_desc[cat_var].upper() + ' - ' + prefix + ' Categories', size=20)\n",
      "        fig.set_size_inches(12, 5)\n",
      "        ax.set_frame_on(False)\n",
      "        ax.set_yticks(np.arange(df_sort.shape[0]) + 0.5, minor=False)\n",
      "        ax.set_xticks(np.arange(df_sort.shape[1]) + 0.5, minor=False)\n",
      "        ax.xaxis.tick_top()\n",
      "        ax.set_xticklabels(df_sort.columns, minor=False)\n",
      "        ax.set_yticklabels(df_sort.index, minor=False)\n",
      "        plt.xticks(rotation=45, ha='left')\n",
      "        ax.grid(False)\n",
      "        for t in ax.yaxis.get_major_ticks():\n",
      "            t.tick1On = False\n",
      "            t.tick2On = False\n",
      "        if save:\n",
      "            plt.savefig(structured_dir + cat_var + '_heatmap.png')\n",
      "\n",
      "\n",
      "def plot_categorical_distribution_charts(df_struct, top_n=10, save=False):\n",
      "    struct_cat_vars = ['nature_of_inj', 'part_of_body', 'src_of_injury', 'event_type', 'evn_factor',\n",
      "                       'hum_factor', 'occ_code', 'sic_desc']\n",
      "    vars_desc = {'site_state': 'Site State', 'site_city': 'Site City', 'nature_of_inj': 'Nature of Injury',\n",
      "             'part_of_body': 'Part of Body', 'src_of_injury': 'Source of Injury', 'event_type': 'Event Type',\n",
      "             'evn_factor': 'Event Factor', 'hum_factor': 'Human Factor', 'occ_code': 'Occupation',\n",
      "             'sic_desc': 'SIC Group Description'}\n",
      "    for i, cat_var in enumerate(struct_cat_vars):\n",
      "        df = df_struct.reset_index().pivot_table('summary_nr', rows=[cat_var], cols=['fatality_ind'],\n",
      "                                                 aggfunc='count').fillna(0)\n",
      "        df.columns = ['Not Fatal', 'Fatal']\n",
      "        num_cats = df.shape[0]\n",
      "        df['Total Accidents'] = df['Not Fatal'] + df['Fatal']\n",
      "        df.columns.name = 'Accident Outcome'\n",
      "        df_top = df.sort_index(by='Total Accidents', ascending=False)[:top_n]\n",
      "        df_rest = df.sort_index(by='Total Accidents', ascending=False)[top_n:]\n",
      "        df_rest = pd.DataFrame(df_rest.sum(), columns=['*** ALL OTHER CATEGORIES ***']).T\n",
      "        df_comb = pd.concat([df_top, df_rest])\n",
      "        df_comb = df_comb.sort_index(by=['Total Accidents'])\n",
      "        df_comb = df_comb.drop(['Total Accidents'], axis=1)\n",
      "        df_norm = df_comb.div(df_comb.sum(axis=1).astype('float'), axis=0)\n",
      "        fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
      "        fig.subplots_adjust(wspace=0.001)\n",
      "        subtitle = 'Top ' + str(min(num_cats, top_n)) + ' Categories Plus All Other'\n",
      "        df_comb.plot(kind='barh', stacked=True, ax=axes[0], alpha=0.5,\n",
      "                     title=vars_desc[cat_var].upper() + '\\n' + subtitle, sort_columns=True)\n",
      "        df_norm.plot(kind='barh', stacked=True, ax=axes[1], alpha=0.4,\n",
      "                     title='Normalized Accident Count\\n ', sort_columns=True)\n",
      "        axes[0].legend(loc='bottom right')\n",
      "        axes[1].legend().set_visible(False)\n",
      "        axes[0].set_xlabel('Accident Count (000\\'s)')\n",
      "        axes[0].xaxis.set_major_formatter(ticker.FuncFormatter(lambda k, pos: ('%.0f') % (k * 1e-3)))\n",
      "        axes[1].xaxis.tick_top()\n",
      "        axes[1].set_xticks(np.arange(0, 1.1, 0.1))\n",
      "        axes[1].set_yticklabels([])\n",
      "        if save:\n",
      "            plt.savefig(structured_dir + cat_var + '_distribution_chart.png')\n",
      "\n",
      "\n",
      "def get_senti_scores():\n",
      "    senti_scores = collections.defaultdict(list)\n",
      "    with open('SentiWordNet_3.0.0_20130122.txt', 'r') as csvfile:\n",
      "        reader = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
      "        for line in reader:\n",
      "            if line[0].startswith(\"#\"):\n",
      "                continue\n",
      "            if len(line) == 1:\n",
      "                continue\n",
      "            POS, ID, PosScore, NegScore, SynsetTerms, Gloss = line\n",
      "            if len(POS) == 0 or len(ID) == 0:\n",
      "                continue\n",
      "            for term in SynsetTerms.split(\" \"):\n",
      "                term = term.split(\"#\")[0]\n",
      "                term = term.replace(\"-\", \" \").replace(\"_\", \" \")\n",
      "                key = \"%s/%s\" % (POS, term)\n",
      "                senti_scores[key].append((float(PosScore), float(NegScore)))\n",
      "    for key, value in senti_scores.iteritems():\n",
      "        senti_scores[key] = np.mean(value, axis=0)\n",
      "    return senti_scores\n",
      "\n",
      "\n",
      "def extract_linguistic_features(documents):\n",
      "    senti_scores = get_senti_scores()\n",
      "    feat_list = []\n",
      "    columns = ['len_doc', 'num_sents', 'num_chars', 'num_tokens', 'num_unique_tokens', 'num_alpha_tokens',\n",
      "               'avg_pos_val', 'avg_neg_val', 'num_nouns', 'num_adjectives', 'num_verbs', 'num_adverbs',\n",
      "               'num_female_prps', 'num_male_prps']\n",
      "    female_preps = ['she', 'her', 'hers', 'herself']\n",
      "    male_preps = ['he', 'him', 'his', 'himself']\n",
      "\n",
      "    for document in documents:\n",
      "\n",
      "        len_doc, num_sents, num_chars, num_tokens, num_unique_tokens, num_alpha_tokens, avg_pos_val, \\\n",
      "        avg_neg_val = 0, 0, 0, 0, 0, 0, 0, 0\n",
      "        num_nouns, num_adjectives, num_verbs, num_adverbs, num_female_prps, num_male_prps = 0, 0, 0, 0, 0, 0\n",
      "\n",
      "        tokens_list = []\n",
      "        pos_vals = []\n",
      "        neg_vals = []\n",
      "\n",
      "        len_doc = len(document)\n",
      "        sents = nltk.sent_tokenize(document)\n",
      "        for sent in sents:\n",
      "            num_sents += 1\n",
      "            tokens = nltk.word_tokenize(sent)\n",
      "            tokens = [punctuation.sub('', w) for w in tokens]\n",
      "            tokens = [w.lower() for w in tokens if len(w) > 0]\n",
      "            tags = nltk.pos_tag(tokens)\n",
      "            for token, tag in tags:\n",
      "                num_tokens += 1\n",
      "                num_chars += len(token)\n",
      "                pos_type = None\n",
      "                p, n = 0, 0\n",
      "                if tag.startswith('NN'):\n",
      "                    num_nouns += 1\n",
      "                    pos_type = 'n'\n",
      "                elif tag.startswith('JJ'):\n",
      "                    num_adjectives += 1\n",
      "                    pos_type = 'a'\n",
      "                elif tag.startswith('VB'):\n",
      "                    num_verbs += 1\n",
      "                    pos_type = 'v'\n",
      "                elif tag.startswith('RB'):\n",
      "                    num_adverbs += 1\n",
      "                    pos_type = 'r'\n",
      "                if token.isalpha():\n",
      "                    num_alpha_tokens += 1\n",
      "                if token.lower() in female_preps:\n",
      "                    num_female_prps += 1\n",
      "                if token.lower() in male_preps:\n",
      "                    num_male_prps += 1\n",
      "                if pos_type is not None:\n",
      "                    sent_word = '%s/%s' % (pos_type, token)\n",
      "                    if sent_word in senti_scores:\n",
      "                        p, n = senti_scores[sent_word]\n",
      "                pos_vals.append(p)\n",
      "                neg_vals.append(n)\n",
      "            tokens_list.extend(tokens)\n",
      "        num_unique_tokens = len(set(tokens_list))\n",
      "        avg_pos_val = np.mean(pos_vals)\n",
      "        avg_neg_val = np.mean(neg_vals)\n",
      "\n",
      "        feat_list.append(\n",
      "            [len_doc, num_sents, num_chars, num_tokens, num_unique_tokens, num_alpha_tokens, avg_pos_val, avg_neg_val,\n",
      "             num_nouns, num_adjectives, num_verbs, num_adverbs, num_female_prps, num_male_prps])\n",
      "    return pd.DataFrame(feat_list, columns=columns)\n",
      "\n",
      "\n",
      "def ie_preprocess(document, morphtype='none', stopwords='yes'):\n",
      "    token_list = []\n",
      "    sents = nltk.sent_tokenize(document)\n",
      "    for sent in sents:\n",
      "        tokens = nltk.word_tokenize(sent)\n",
      "        tokens = [punctuation.sub('', w) for w in tokens]\n",
      "        tokens = [w.lower() for w in tokens if w.isalpha() and len(w) > 2]\n",
      "        if stopwords == 'yes':\n",
      "            tokens = [w for w in tokens if w not in english_stopwords]\n",
      "        if morphtype == 'lemma':\n",
      "            tokens = [english_lemmatizer.lemmatize(w) for w in tokens]\n",
      "        elif morphtype == 'stem':\n",
      "            tokens = [english_stemmer.stem(w) for w in tokens]\n",
      "        else:\n",
      "            pass\n",
      "        token_list.extend(tokens)\n",
      "    return token_list\n",
      "\n",
      "\n",
      "def join_abstract_lines(group):\n",
      "    return ' '.join(group.abstract_text).strip()\n",
      "\n",
      "def get_description_token_table(df_txt):\n",
      "    desc_tokens_list = []\n",
      "    stemmed_exclude_tokens = get_stemmed_exlude_tokens()\n",
      "    columns = ['summary_nr', 'fatality_ind', 'var_name', 'token', 'stem', 'excluded']\n",
      "    for i, txt in enumerate(zip(df_txt.index, df_txt.fatality_ind, df_txt.event_desc)):\n",
      "        tokens = ie_preprocess(txt[2])\n",
      "        for token in tokens:\n",
      "            stemmed_token = english_stemmer.stem(token)\n",
      "            if stemmed_token in stemmed_exclude_tokens:\n",
      "                excluded = 1\n",
      "            else:\n",
      "                excluded = 0\n",
      "            desc_tokens_list.append([txt[0], txt[1], 'desc', token, stemmed_token, excluded])\n",
      "    df_desc_tokens = pd.DataFrame(desc_tokens_list, columns=columns).set_index('summary_nr')\n",
      "    return df_desc_tokens\n",
      "\n",
      "\n",
      "def get_summary_token_table(df_txt):\n",
      "    summ_tokens_list = []\n",
      "    stemmed_exclude_tokens = get_stemmed_exlude_tokens()\n",
      "    columns = ['summary_nr', 'fatality_ind', 'var_name', 'token', 'stem', 'excluded']\n",
      "    for i, txt in enumerate(zip(df_txt.index, df_txt.fatality_ind, df_txt.summary_txt)):\n",
      "        tokens = ie_preprocess(txt[2])\n",
      "        for token in tokens:\n",
      "            stemmed_token = english_stemmer.stem(token)\n",
      "            if stemmed_token in stemmed_exclude_tokens:\n",
      "                summ_tokens_list.append([txt[0], txt[1], 'summ', token, stemmed_token, 1])\n",
      "    df_summ_tokens = pd.DataFrame(summ_tokens_list, columns=columns).set_index('summary_nr')\n",
      "    return df_summ_tokens\n",
      "\n",
      "\n",
      "def plot_svd_concepts(df, partition, svd_name, graphs_dir, save=False):\n",
      "    fig, axes = plt.subplots(3, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
      "    fig.suptitle('SVD Component Scatterplots of Top Four Concepts\\n' + svd_name + ' - ' + partition.title(), size=20)\n",
      "    for row, col, cx, cy in [(0, 0, 1, 2), (1, 0, 1, 3), (2, 0, 1, 4), (0, 1, 2, 3), (1, 1, 2, 4), (2, 1, 3, 4)]:\n",
      "        axes[row, col].scatter(df[(df.partition == partition) & (df.fatality_ind == 0)]['SVD_Comp_' + str(cx)],\n",
      "                               df[(df.partition == partition) & (df.fatality_ind == 0)]['SVD_Comp_' + str(cy)],\n",
      "                               c='g', label='Non-Fatal', alpha=0.01)\n",
      "        axes[row, col].scatter(df[(df.partition == partition) & (df.fatality_ind == 1)]['SVD_Comp_' + str(cx)],\n",
      "                               df[(df.partition == partition) & (df.fatality_ind == 1)]['SVD_Comp_' + str(cy)],\n",
      "                               c='r', label='Fatal', alpha=0.01)\n",
      "        axes[row, col].set_xlabel('Concept ' + str(cx))\n",
      "        axes[row, col].set_ylabel('Concept ' + str(cy))\n",
      "        #fig.tight_layout(pad=0.4, w_pad=1.0, h_pad=1.0)\n",
      "        plt.subplots_adjust(top=0.9)\n",
      "        if save:\n",
      "            fig.savefig(graphs_dir + 'svd_concept_graphs_' + partition + '_' + svd_name + '.png')\n",
      "\n",
      "\n",
      "def process_model_batch(feature_sets, clfs, batch_dir):\n",
      "    met_list = []\n",
      "    res_list = []\n",
      "    cols_dict = {}\n",
      "\n",
      "    for fset_name, df in feature_sets.items():\n",
      "        print fset_name + ' begin: ' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
      "\n",
      "        cols_dict[fset_name] = df.drop(['partition', 'fatality_ind'], axis=1).columns\n",
      "\n",
      "        X_train = df[df.partition == 'train'].drop(['partition', 'fatality_ind'], axis=1)\n",
      "        y_train = df[df.partition == 'train'].fatality_ind\n",
      "        X_test = df[df.partition == 'test'].drop(['partition', 'fatality_ind'], axis=1)\n",
      "        y_test = df[df.partition == 'test'].fatality_ind\n",
      "\n",
      "        for model_name, model in clfs.items():\n",
      "            print '.....' + model_name + ' begin: ' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
      "\n",
      "            pair_name = fset_name + ' - ' + model_name\n",
      "            try:\n",
      "                t0 = time()\n",
      "                model.fit(X_train, y_train)\n",
      "                duration = time() - t0\n",
      "                test_pred = model.predict(X_test)\n",
      "                test_pred_prob = model.predict_proba(X_test)\n",
      "                cm = confusion_matrix(y_test, test_pred)\n",
      "\n",
      "                pickle.dump(model, open(batch_dir + pair_name + '.p', 'wb'))\n",
      "\n",
      "                met_list.append([pair_name, fset_name, model_name, duration, round(np.mean(y_test) * 100, 1),\n",
      "                                 accuracy_score(y_test, test_pred), precision_score(y_test, test_pred),\n",
      "                                 recall_score(y_test, test_pred), f1_score(y_test, test_pred),\n",
      "                                 cm[0, 0], cm[1, 0], cm[0, 1], cm[1, 1]])\n",
      "\n",
      "                dfr = pd.DataFrame({'summary_nr': X_test.index, 'pair_name': pair_name, 'fset_name': fset_name,\n",
      "                                    'model_name': model_name, 'target_ind': y_test, 'target_pred': test_pred,\n",
      "                                    'pred_0_prob': test_pred_prob[:, 0], 'pred_1_prob': test_pred_prob[:, 1]})\n",
      "                res_list.append(dfr)\n",
      "            except:\n",
      "                print '..... ### process model error: ', fset_name, model_name\n",
      "\n",
      "            print '.....' + model_name + ' end: ' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
      "        print fset_name + ' end: ' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
      "        print ''\n",
      "\n",
      "    df_met = pd.DataFrame(met_list, columns=['pair_name', 'fset_name', 'model_name', 'duration', 'act_target_pct',\n",
      "                                             'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'TN',\n",
      "                                             'FN', 'FP', 'TP'])\n",
      "    df_res = pd.concat(res_list).set_index('summary_nr')\n",
      "\n",
      "    pickle.dump(df_res, open(batch_dir + 'df_results.p', 'wb'))\n",
      "    pickle.dump(df_met, open(batch_dir + 'df_metrics.p', 'wb'))\n",
      "    pickle.dump(cols_dict, open(batch_dir + 'feature_set_columns.p', 'wb'))\n",
      "\n",
      "\n",
      "def get_combined_separate_fsets(feature_sets, fs_fn='pct', ptile=10, nFeatures=5, score_fn=f_classif):\n",
      "    df_lst = []\n",
      "    for fset_name, df in feature_sets.items():\n",
      "        X_train = df[df.partition == 'train'].drop(['partition', 'fatality_ind'], axis=1)\n",
      "        y_train = df[df.partition == 'train'].fatality_ind\n",
      "        df_X = df.drop(['partition', 'fatality_ind'], axis=1)\n",
      "        if fs_fn == 'pct':\n",
      "            featureSelector = SelectPercentile(score_func=score_fn, percentile=ptile)\n",
      "        else:\n",
      "            featureSelector = SelectKBest(score_func=score_fn, k=nFeatures)\n",
      "        featureSelector.fit(X_train, y_train)\n",
      "        fs = featureSelector.transform(df.drop(['partition', 'fatality_ind'], axis=1))\n",
      "        cols_fs = df_X.columns[list(featureSelector.get_support(indices=True))]\n",
      "        cols_fs_ref = [fset_name + ' ' + c for c in cols_fs]\n",
      "        df_fs = pd.DataFrame(fs, index=df_X.index, columns=cols_fs_ref)\n",
      "        df_lst.append(df_fs)\n",
      "    df_comb = df[['partition', 'fatality_ind']].join(pd.concat(df_lst, axis=1))\n",
      "    return df_comb\n",
      "\n",
      "\n",
      "def get_combined_united_fsets(feature_sets, fs_fn='pct', ptile=10, nFeatures=5, score_fn=f_classif):\n",
      "    df_lst = []\n",
      "    for fset_name, df in feature_sets.items():\n",
      "        df_X = df.drop(['partition', 'fatality_ind'], axis=1)\n",
      "        df_X.columns = [fset_name + ' ' + c for c in df_X.columns]\n",
      "        df_lst.append(df_X)\n",
      "    df_comb = df[['partition', 'fatality_ind']].join(pd.concat(df_lst, axis=1))\n",
      "    X_train = df_comb[df_comb.partition == 'train'].drop(['partition', 'fatality_ind'], axis=1)\n",
      "    y_train = df_comb[df_comb.partition == 'train'].fatality_ind\n",
      "    if fs_fn == 'pct':\n",
      "        featureSelector = SelectPercentile(score_func=score_fn, percentile=ptile)\n",
      "    else:\n",
      "        featureSelector = SelectKBest(score_func=score_fn, k=nFeatures)\n",
      "    featureSelector.fit(X_train, y_train)\n",
      "    fs = featureSelector.transform(df_comb.drop(['partition', 'fatality_ind'], axis=1))\n",
      "    cols_fs = df_comb.drop(['partition', 'fatality_ind'], axis=1).columns[\n",
      "        list(featureSelector.get_support(indices=True))]\n",
      "    df_fs = pd.DataFrame(fs, index=df_comb.index, columns=cols_fs)\n",
      "    return df_comb[['partition', 'fatality_ind']].join(df_fs)\n",
      "\n",
      "\n",
      "class StemmedCountVectorizer(CountVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
      "\n",
      "\n",
      "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
      "\n",
      "\n",
      "class LemmatizedCountVectorizer(CountVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(LemmatizedCountVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (english_lemmatizer.lemmatize(w) for w in analyzer(doc))\n",
      "\n",
      "\n",
      "class LemmatizedTfidfVectorizer(TfidfVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(LemmatizedTfidfVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (english_lemmatizer.lemmatize(w) for w in analyzer(doc))\n",
      "\n",
      "\n",
      "def get_outcome(ind_pred):\n",
      "    ind = ind_pred[0]\n",
      "    pred = ind_pred[1]\n",
      "    if ind == 0 and pred == 0:\n",
      "        return 'TN'\n",
      "    elif ind == 1 and pred == 1:\n",
      "        return 'TP'\n",
      "    elif ind == 1 and pred == 0:\n",
      "        return 'FN'\n",
      "    else:\n",
      "        return 'FP'\n",
      "\n",
      "\n",
      "def get_tree_model_info(fsets, clfs, model_dict, cols_dict):\n",
      "    df_list = []\n",
      "    for fset in fsets:\n",
      "        for clf in clfs:\n",
      "            if clf in ['RanFst', 'DTree']:\n",
      "                pair_name = fset + ' - ' + clf\n",
      "                try:\n",
      "                    df = pd.DataFrame({'pair_name': pair_name, 'importance': model_dict[pair_name].feature_importances_,\n",
      "                                       'feature': cols_dict[fset]})\n",
      "                    df = df.sort_index(by=['importance'], ascending=False)\n",
      "                    df_list.append(df)\n",
      "                except:\n",
      "                    print pair_name, ' model does not exist...'\n",
      "    df_tree_info = pd.concat(df_list)\n",
      "    return df_tree_info\n",
      "\n",
      "\n",
      "def plot_tree_importance(fsets, clfs, top_n, model_dict, cols_dict, graph_files_dir, save=False):\n",
      "    for fset in fsets:\n",
      "        for clf in clfs:\n",
      "            if clf in ['RanFst', 'DTree']:\n",
      "                pair_name = fset + ' - ' + clf\n",
      "                try:\n",
      "                    fig = plt.figure()\n",
      "                    tree_imp = pd.Series(model_dict[pair_name].feature_importances_,\n",
      "                                         index=cols_dict[fset]).order(ascending=False)[:top_n]\n",
      "                    tree_imp.order(ascending=True).plot(kind='barh', title='Feature Set: ' + fset + '\\n' + clf +\n",
      "                                                                           ' Feature Importance (Top ' + str(\n",
      "                        top_n) + ')')\n",
      "                    if save:\n",
      "                        fig.savefig(graph_files_dir + 'feat imp - ' + pair_name + '.png')\n",
      "                except:\n",
      "                    print pair_name, ' model does not exist...'\n",
      "\n",
      "\n",
      "def get_logreg_model_info(fsets, clfs, model_dict, cols_dict):\n",
      "    df_list = []\n",
      "    for fset in fsets:\n",
      "        for clf in clfs:\n",
      "            if clf in ['LogReg']:\n",
      "                pair_name = fset + ' - ' + clf\n",
      "                try:\n",
      "                    df = pd.DataFrame({'pair_name': pair_name, 'coefficient': model_dict[pair_name].coef_[0].T,\n",
      "                                       'feature': cols_dict[fset]})\n",
      "                    df['intercept'] = model_dict[pair_name].intercept_[0]\n",
      "                    df_list.append(df)\n",
      "                except:\n",
      "                    print pair_name, ' model does not exist...'\n",
      "    df_logreg_info = pd.concat(df_list)\n",
      "    return df_logreg_info\n",
      "\n",
      "\n",
      "def plot_logreg_coef_importance(fsets, clfs, df_logreg, ends_n, model_dict, cols_dict, graph_files_dir, save=False):\n",
      "    for fset in fsets:\n",
      "        for clf in clfs:\n",
      "            if clf in ['LogReg']:\n",
      "                pair_name = fset + ' - ' + clf\n",
      "                fig = plt.figure()\n",
      "                df = df_logreg[df_logreg.pair_name == pair_name][['coefficient', 'feature']].set_index(['coefficient'])\n",
      "                if len(df) > ends_n * 2:\n",
      "                    df_neg = df.sort_index(ascending=True)[:ends_n]\n",
      "                    df_pos = df.sort_index(ascending=False)[:ends_n]\n",
      "                    df = pd.concat([df_neg, df_pos])\n",
      "                    df = df.sort_index().reset_index().set_index(['feature'])\n",
      "                    ax = df.plot(kind='barh', title='Feature Set: ' + fset + '\\n' + clf + ' Feature Importance (Top '\\\n",
      "                                  + str(min(ends_n * 2, len(df))) + ')')\n",
      "                    ax.set_ylabel('')\n",
      "                    if save:\n",
      "                        fig.savefig(graph_files_dir + 'feat imp - ' + pair_name + '.png')\n",
      "\n",
      "\n",
      "def gains_curve(y_test, pos_class_probas):\n",
      "    df = pd.DataFrame({'ind': y_test, 'prob': pos_class_probas})\n",
      "    df['prob_rank'] = df['prob'].rank(method='first', ascending=False)\n",
      "    df['n_grp'] = pd.qcut(df['prob_rank'], 100).labels + 1\n",
      "    dfg = df.groupby('n_grp')['ind', 'obs'].sum()\n",
      "    dfg['cum_actual'] = dfg['ind'].cumsum()\n",
      "    dfg['pct_actual'] = dfg['cum_actual'].astype(float) / dfg['cum_actual'].max() * 100\n",
      "    dfg = dfg.reset_index()\n",
      "    return dfg.n_grp, dfg.pct_actual\n",
      "\n",
      "\n",
      "def plot_gains_charts(df_result, classifiers, feature_sets, grouping, graph_files_dir, save=False, dfs=None, dfsn=''):\n",
      "    target_mean = np.mean(df_result.target_ind)\n",
      "\n",
      "    if grouping == 'fset':\n",
      "        for fset in feature_sets:\n",
      "            fig, axes = plt.subplots(1, 1, figsize=(10, 7))\n",
      "            if dfs is not None:\n",
      "                xi, yi = gains_curve(dfs.target_ind, dfs.pred_1_prob)\n",
      "                axes.plot(xi, yi, label=dfsn)\n",
      "            for clf in classifiers:\n",
      "                try:\n",
      "                    df = df_result[(df_result.model_name == clf) & (df_result.fset_name == fset)]\n",
      "                    xi, yi = gains_curve(df.target_ind, df.pred_1_prob)\n",
      "                    axes.plot(xi, yi, label=clf)\n",
      "                except:\n",
      "                    pass\n",
      "            plt.title('Feature Set: ' + fset + '\\nCumulative Gains Chart')\n",
      "            plt.grid(True)\n",
      "            plt.plot(range(100), range(100), 'r-.', lw=3, label='Baseline Model')\n",
      "            path = Path([(0., 0.), (target_mean * 100, 100.), (100., 100.)])\n",
      "            patch = patches.PathPatch(path, facecolor='black', alpha=0.05, lw=3, label='Best Model')\n",
      "            axes.add_patch(patch)\n",
      "            plt.yticks(range(0, 105, 5))\n",
      "            plt.xticks(range(0, 105, 5))\n",
      "            plt.xlabel('% Accidents')\n",
      "            plt.ylabel('% Fatalities')\n",
      "            plt.legend(loc=\"lower right\")\n",
      "            leg = plt.gca().get_legend()\n",
      "            leg.set_title('Classification Model')\n",
      "            ltext = leg.get_texts()\n",
      "            plt.setp(ltext, fontsize='small')\n",
      "            if save:\n",
      "                plt.savefig(graph_files_dir + 'gains chart - ' + fset + '.png')\n",
      "\n",
      "    if grouping == 'clf':\n",
      "        for clf in classifiers:\n",
      "            fig, axes = plt.subplots(1, 1, figsize=(10, 7))\n",
      "            if dfs is not None:\n",
      "                xi, yi = gains_curve(dfs.target_ind, dfs.pred_1_prob)\n",
      "                axes.plot(xi, yi, label=dfsn)\n",
      "            for fset in feature_sets:\n",
      "                try:\n",
      "                    df = df_result[(df_result.model_name == clf) & (df_result.fset_name == fset)]\n",
      "                    xi, yi = gains_curve(df.target_ind, df.pred_1_prob)\n",
      "                    axes.plot(xi, yi, label=fset)\n",
      "                except:\n",
      "                    pass\n",
      "            plt.title('Classification Model: ' + clf + '\\nCumulative Gains Chart')\n",
      "            plt.grid(True)\n",
      "            plt.plot(range(100), range(100), 'r-.', lw=3, label='Baseline Model')\n",
      "            path = Path([(0., 0.), (target_mean * 100, 100.), (100., 100.)])\n",
      "            patch = patches.PathPatch(path, facecolor='black', alpha=0.05, lw=3, label='Best Model')\n",
      "            axes.add_patch(patch)\n",
      "            plt.yticks(range(0, 105, 5))\n",
      "            plt.xticks(range(0, 105, 5))\n",
      "            plt.xlabel('% Accidents')\n",
      "            plt.ylabel('% Fatalities')\n",
      "            plt.legend(loc=\"lower right\")\n",
      "            leg = plt.gca().get_legend()\n",
      "            leg.set_title('Feature Set')\n",
      "            ltext = leg.get_texts()\n",
      "            plt.setp(ltext, fontsize='small')\n",
      "            if save:\n",
      "                plt.savefig(graph_files_dir + 'gains chart - ' + clf + '.png')\n",
      "\n",
      "\n",
      "def plot_precision_recall_charts(df_result, classifiers, feature_sets, grouping, graph_files_dir, save=False):\n",
      "    if grouping == 'fset':\n",
      "        for fset in feature_sets:\n",
      "            fig, axes = plt.subplots(1, 1, figsize=(10, 7))\n",
      "            for clf in classifiers:\n",
      "                try:\n",
      "                    df = df_result[(df_result.model_name == clf) & (df_result.fset_name == fset)]\n",
      "                    precision, recall, thresholds = precision_recall_curve(df.target_ind, df.pred_1_prob)\n",
      "                    axes.plot(recall, precision, label=clf)\n",
      "                except:\n",
      "                    pass\n",
      "            plt.title('Feature Set: ' + fset + '\\nPrecision Recall Chart')\n",
      "            plt.grid(True)\n",
      "            plt.yticks(np.arange(0, 1.1, 0.1))\n",
      "            plt.xticks(np.arange(0, 1.1, 0.1))\n",
      "            plt.xlabel('Recall')\n",
      "            plt.ylabel('Precision')\n",
      "            plt.legend(loc='lower left')\n",
      "            leg = plt.gca().get_legend()\n",
      "            leg.set_title('Classification Model')\n",
      "            ltext = leg.get_texts()\n",
      "            plt.setp(ltext, fontsize='small')\n",
      "            if save:\n",
      "                plt.savefig(graph_files_dir + 'pr chart - ' + fset + '.png')\n",
      "\n",
      "    if grouping == 'clf':\n",
      "        for clf in classifiers:\n",
      "            fig, axes = plt.subplots(1, 1, figsize=(10, 7))\n",
      "            for fset in feature_sets:\n",
      "                try:\n",
      "                    df = df_result[(df_result.model_name == clf) & (df_result.fset_name == fset)]\n",
      "                    precision, recall, thresholds = precision_recall_curve(df.target_ind, df.pred_1_prob)\n",
      "                    axes.plot(recall, precision, label=fset)\n",
      "                except:\n",
      "                    pass\n",
      "            plt.title('Classification Model: ' + clf + '\\nPrecision Recall Chart')\n",
      "            plt.grid(True)\n",
      "            plt.yticks(np.arange(0, 1.1, 0.1))\n",
      "            plt.xticks(np.arange(0, 1.1, 0.1))\n",
      "            plt.xlabel('Recall')\n",
      "            plt.ylabel('Precision')\n",
      "            plt.legend(loc='lower left')\n",
      "            leg = plt.gca().get_legend()\n",
      "            leg.set_title('Feature Set')\n",
      "            ltext = leg.get_texts()\n",
      "            plt.setp(ltext, fontsize='small')\n",
      "            if save:\n",
      "                plt.savefig(graph_files_dir + 'pr chart - ' + clf + '.png')\n",
      "\n",
      "\n",
      "def get_mrp_results(df_results):\n",
      "    mrp_results = []\n",
      "    for mrp in range(25, 80, 5):\n",
      "        df = df_results.reset_index().groupby(['summary_nr', 'fset_name', 'target_ind'], as_index=False) \\\n",
      "            ['pred_0_prob', 'pred_1_prob'].mean()\n",
      "        df['model_name'] = 'MRP ' + str(mrp)\n",
      "        df['pair_name'] = df.fset_name + ' - ' + df['model_name']\n",
      "        df['target_pred'] = df['pred_1_prob'].map(lambda x: 1 if x * 100 >= mrp else 0)\n",
      "        df = df[['summary_nr', 'fset_name', 'model_name', 'pair_name', 'pred_0_prob', 'pred_1_prob', 'target_ind',\n",
      "                 'target_pred']]\n",
      "        mrp_results.append(df)\n",
      "    df_mrp = pd.concat(mrp_results)\n",
      "    return df_mrp.set_index('summary_nr')\n",
      "\n",
      "\n",
      "def get_voting_results(df_results, num_models):\n",
      "    voting_results = []\n",
      "    for vote in range(1, num_models + 1):\n",
      "        df = df_results.reset_index().groupby(['summary_nr', 'fset_name', 'target_ind'], as_index=False) \\\n",
      "            ['pred_0_prob', 'pred_1_prob', 'target_pred'].sum()\n",
      "        df['model_name'] = 'Vote ' + str(vote) + '+'\n",
      "        df['pair_name'] = df.fset_name + ' - ' + df['model_name']\n",
      "        df['target_pred'] = df['target_pred'].map(lambda x: 1 if x >= vote else 0)\n",
      "        df['pred_0_prob'] = df['pred_0_prob'] / num_models\n",
      "        df['pred_1_prob'] = df['pred_1_prob'] / num_models\n",
      "        df = df[['summary_nr', 'fset_name', 'model_name', 'pair_name', 'pred_0_prob', 'pred_1_prob', 'target_ind',\n",
      "                 'target_pred']]\n",
      "        voting_results.append(df)\n",
      "    df_vote = pd.concat(voting_results)\n",
      "    return df_vote.set_index('summary_nr')\n",
      "\n",
      "\n",
      "def plot_combination_model_chart(df_mrp_metrics, df_voting_metrics, feature_sets,\\\n",
      "                                 num_models, graph_files_dir, save=False):\n",
      "    fig, axes = plt.subplots(1, 2, figsize=(9, 4), sharey=True)\n",
      "    for fset in feature_sets:\n",
      "        dfm = df_mrp_metrics[df_mrp_metrics.fset_name == fset]\n",
      "        dfm['xi'] = dfm.model_name.map(lambda x: int(x[-2:]))\n",
      "        axes[0].plot(dfm.xi, dfm.accuracy_score, label=fset, marker='o')\n",
      "        axes[0].set_xticks(range(25, 80, 5))\n",
      "        axes[0].set_xlabel('MRP Threshold')\n",
      "        axes[0].set_ylabel('Accuracy Score')\n",
      "        axes[0].set_title('Mean Response Probababity Model Results')\n",
      "        axes[0].set_xlim([25, 75])\n",
      "        axes[0].grid(True)\n",
      "        axes[0].legend(loc='lower center', prop={'size': 10}).set_title('Feature Set')\n",
      "        dfv = df_voting_metrics[df_voting_metrics.fset_name == fset]\n",
      "        dfv['xi'] = dfv.model_name.map(lambda x: int(x[-2:-1]))\n",
      "        axes[1].plot(dfv.xi, dfv.accuracy_score, label=fset, marker='o')\n",
      "        axes[1].set_xticks(range(0, 8, 1))\n",
      "        axes[1].set_xlabel('Voting Model [ >= X Agree ]')\n",
      "        axes[1].set_title('Voting Model Results')\n",
      "        axes[1].set_xlim([1, num_models])\n",
      "        axes[1].grid(True)\n",
      "        fig.tight_layout(pad=0.4, w_pad=1.0, h_pad=1.0)\n",
      "        if save:\n",
      "            plt.savefig(graph_files_dir + 'mrp voting results chart - ' + fset + '.png')\n",
      "\n",
      "\n",
      "def plot_outcome_comparison(df_outcome, graph_files_dir, figsize=(10, 4), save=False):\n",
      "    fig, ax = plt.subplots(figsize=figsize)\n",
      "    fig.subplots_adjust(top=.8)\n",
      "    fig.suptitle('Outcome Comparison - Best \"Structured\" Model Versus All Others', fontsize=12)\n",
      "    ax.set_frame_on(False)\n",
      "    ax.set_xlabel('Accidents Ordered by the Best \"Structured\" Model\\n\\\n",
      "                   Probability of Fatal Accident (High to Low)', size=12)\n",
      "    ax.set_yticks(np.arange(df_outcome.shape[0]) + 0.5, minor=False)\n",
      "    ax.set_xlim([0, len(df_outcome.T)])\n",
      "    ax.set_xticks(np.arange(0, len(df_outcome), 5000))\n",
      "    ax.set_yticklabels(df_outcome.columns, minor=False)\n",
      "    cmap = mpl.colors.ListedColormap(['floralwhite', 'red', 'blue', 'lightgrey'])\n",
      "    bounds = [-2.5, -1.5, 0, 1.5, 2.5]\n",
      "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
      "    im = ax.pcolor(df_outcome.T, cmap=cmap, norm=norm)\n",
      "    for t in ax.yaxis.get_major_ticks():\n",
      "        t.tick1On = False\n",
      "        t.tick2On = False\n",
      "    for t in ax.xaxis.get_major_ticks():\n",
      "        t.tick1On = False\n",
      "        t.tick2On = False\n",
      "\n",
      "    fig.text(0.16, 0.85, 'True Positive', fontsize=12, bbox={'facecolor': 'floralwhite', 'pad': 10})\n",
      "    fig.text(0.35, 0.85, 'False Positive', fontsize=12, bbox={'facecolor': 'blue', 'pad': 10, 'alpha': 0.5})\n",
      "    fig.text(0.54, 0.85, 'False Negative', fontsize=12, bbox={'facecolor': 'red', 'pad': 10})\n",
      "    fig.text(0.75, 0.85, 'True Negative', fontsize=12, bbox={'facecolor': 'lightgrey', 'pad': 10})\n",
      "    if save:\n",
      "        plt.savefig(graph_files_dir + 'pcolor_outcome_compare.png')\n",
      "\n",
      "\n",
      "def plot_best_FN(df_struct_FN, graph_files_dir, save=False):\n",
      "    fig, ax = plt.subplots(figsize=(10, 4))\n",
      "    plt.subplots_adjust(top=0.88)\n",
      "    fig.suptitle('Best \"Structured\" Model False Negatives (' + str(len(df_struct_FN)) +\n",
      "                 ')\\nIncorrect Classification of Accident as Non-Fatal', size=12)\n",
      "    ax.set_frame_on(False)\n",
      "    ax.set_xlabel('Accidents Ordered by the Best \"Structured\" Model\\n\\\n",
      "                   Probability of Fatal Accident (High to Low)', size=12)\n",
      "    ax.set_yticks(np.arange(df_struct_FN.shape[0]) + 0.5, minor=False)\n",
      "    ax.set_xlim([0, len(df_struct_FN)])\n",
      "    ax.set_xticks(np.arange(0, len(df_struct_FN), 500))\n",
      "    ax.set_yticklabels(df_struct_FN.columns, minor=False)\n",
      "    im = ax.pcolor(df_struct_FN.T, cmap=plt.cm.RdYlGn)\n",
      "    cbar = fig.colorbar(im)\n",
      "    cbar.set_label('Probability of Fatal Accident', rotation=90, size=12)\n",
      "    for t in ax.yaxis.get_major_ticks():\n",
      "        t.tick1On = False\n",
      "        t.tick2On = False\n",
      "    if save:\n",
      "        plt.savefig(graph_files_dir + 'pcolor_FN.png')\n",
      "\n",
      "\n",
      "def plot_best_FP(df_struct_FP, graph_files_dir, save=False):\n",
      "    fig, ax = plt.subplots(figsize=(10, 4))\n",
      "    plt.subplots_adjust(top=0.88)\n",
      "    fig.suptitle('Best \"Structured\" Model False Positives (' + str(len(df_struct_FP)) +\n",
      "                 ')\\nIncorrect Classification of Accident as Fatal', size=12)\n",
      "    ax.set_frame_on(False)\n",
      "    ax.set_xlabel('Accidents Ordered by the Best \"Structured\" Model\\n\\\n",
      "                   Probability of Non-Fatal Accident (High to Low)', size=12)\n",
      "    ax.set_yticks(np.arange(df_struct_FP.shape[0]) + 0.5, minor=False)\n",
      "    ax.set_xlim([0, len(df_struct_FP)])\n",
      "    ax.set_xticks(np.arange(0, len(df_struct_FP), 500))\n",
      "    ax.set_yticklabels(df_struct_FP.columns, minor=False)\n",
      "    im = ax.pcolor(df_struct_FP.T, cmap=plt.cm.RdYlGn)\n",
      "    cbar = fig.colorbar(im)\n",
      "    cbar.set_label('Probability of Non-Fatal Accident', rotation=90, size=12)\n",
      "    for t in ax.yaxis.get_major_ticks():\n",
      "        t.tick1On = False\n",
      "        t.tick2On = False\n",
      "    if save:\n",
      "        plt.savefig(graph_files_dir + 'pcolor_FP.png')\n",
      "\n",
      "\n",
      "def get_model_training_info(batch_dir):\n",
      "    df_results = pickle.load(open(batch_dir + 'df_results.p', 'rb'))\n",
      "    df_metrics = pickle.load(open(batch_dir + 'df_metrics.p', 'rb'))\n",
      "    col_dict = pickle.load(open(batch_dir + 'feature_set_columns.p', 'rb'))\n",
      "    fsets = list(df_results.fset_name.unique())\n",
      "    clfs = list(df_results.model_name.unique())\n",
      "    model_dict = {}\n",
      "    for clf in clfs:\n",
      "        for fset in fsets:\n",
      "            pair_name = fset + ' - ' + clf\n",
      "            try:\n",
      "                model_dict[pair_name] = pickle.load(open(batch_dir + pair_name + '.p', 'rb'))\n",
      "            except:\n",
      "                print pair_name, ' model does not exist...'\n",
      "    return df_results, df_metrics, col_dict, model_dict, fsets, clfs\n",
      "\n",
      "\n",
      "def get_combination_metrics(df_combination_results):\n",
      "    combination_metrics = []\n",
      "    for group, data in df_combination_results.groupby(['pair_name', 'fset_name', 'model_name']):\n",
      "        y_test = data.target_ind\n",
      "        test_pred = data.target_pred\n",
      "        cm = confusion_matrix(y_test, test_pred)\n",
      "        combination_metrics.append([group[0], group[1], group[2], 0,\n",
      "                                    round(np.mean(y_test) * 100, 1), accuracy_score(y_test, test_pred),\n",
      "                                    precision_score(y_test, test_pred), recall_score(y_test, test_pred),\n",
      "                                    f1_score(y_test, test_pred), cm[0, 0], cm[1, 0], cm[0, 1], cm[1, 1]])\n",
      "        columns = ['pair_name', 'fset_name', 'model_name', 'duration', 'act_target_pct', 'accuracy_score',\n",
      "                   'precision_score', 'recall_score', 'f1_score', 'TN', 'FN', 'FP', 'TP']\n",
      "    df_combination_metrics = pd.DataFrame(combination_metrics, columns=columns)\n",
      "    return df_combination_metrics\n",
      "\n",
      "\n",
      "def get_best_models(group, top_n, score_fn):\n",
      "    return group.sort_index(by=[score_fn], ascending=False)[:top_n]\n",
      "\n",
      "\n",
      "def get_model_type(model_name):\n",
      "    if 'mrp' in model_name.lower():\n",
      "        return 'mrp'\n",
      "    elif 'vote' in model_name.lower():\n",
      "        return 'vote'\n",
      "    else:\n",
      "        return 'base'\n",
      "\n",
      "def plot_average_sentiment(df_ling, partition):\n",
      "    plt.figure()\n",
      "    dfs = df_ling[df_ling.partition==partition]\n",
      "    plt.scatter(dfs.avg_neg_val[dfs.fatality_ind == 0], \\\n",
      "                dfs.avg_pos_val[dfs.fatality_ind == 0], c='g', label='Not Fatal', alpha=0.30)\n",
      "    plt.scatter(dfs.avg_neg_val[dfs.fatality_ind == 1], \\\n",
      "                dfs.avg_pos_val[dfs.fatality_ind == 1], c='r', label='Fatal', alpha = 0.30)\n",
      "    plt.xlim([.02,.11])\n",
      "    plt.ylim([.02,.11])\n",
      "    plt.legend()\n",
      "    plt.title('Avg Negative Sentiment VS Avg Positive Sentiment\\n' + partition.upper() + ' Set')\n",
      "\n",
      "def plot_pca(df_ling, partition):\n",
      "    plt.figure()\n",
      "    dfs = df_ling[df_ling.partition==partition]\n",
      "    plt.scatter(dfs.PCA_Comp_1[dfs.fatality_ind==0], dfs.PCA_Comp_2[dfs.fatality_ind==0], c='g', label='Not Fatal',alpha=0.1)\n",
      "    plt.scatter(dfs.PCA_Comp_1[dfs.fatality_ind==1], dfs.PCA_Comp_2[dfs.fatality_ind==1], c='r', label='Fatal',alpha=0.1)\n",
      "    plt.xlabel('Principal Component 1')\n",
      "    plt.ylim([-5,10])\n",
      "    plt.ylabel('Principal Component 2')\n",
      "    plt.legend()\n",
      "    plt.title('PCA - ' + partition.upper() + ' Set')\n",
      "\n",
      "def plot_scatter_var1_vs_var2(df, var1, var2, partition, title):\n",
      "    plt.figure()\n",
      "    dfs = df[df.partition==partition]\n",
      "    plt.scatter(dfs[var1][dfs.fatality_ind == 0], \\\n",
      "                dfs[var2][dfs.fatality_ind == 0], c='g', label='Not Fatal', alpha=0.30)\n",
      "    plt.scatter(dfs[var1][dfs.fatality_ind == 1], \\\n",
      "                dfs[var2][dfs.fatality_ind == 1], c='r', label='Fatal', alpha = 0.30)\n",
      "    plt.legend()\n",
      "    plt.title(title+ '\\n' + partition.upper() + ' Set')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
